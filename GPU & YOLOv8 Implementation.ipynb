{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "219147db",
   "metadata": {},
   "source": [
    "# GARBAGE DETECTION "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a85b7cb",
   "metadata": {},
   "source": [
    "## GPU AND YOLO V8 IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfb700f",
   "metadata": {},
   "source": [
    "YOLOv8 uses PyTorch, so before installing it's always a good idea to check the system requirements needed. \n",
    "\n",
    "To use the GPU, we will need to understand what type of GPU does our computer have. If we have an NVIDIA GPU, then we use the CUDA toolkit, as well as the CUDNN libraries. If we have an AMD GPU, there is an open source website called Open CL.\n",
    "\n",
    "It is important to check what version does PyTorch support for CUDA, as we will not be using the latest version (12.1 as of writing).\n",
    "\n",
    "Here is a link to installing PyTorch: https://pytorch.org/get-started/locally/\n",
    "\n",
    "Here is a link to the CUDA Toolkit Archive: https://developer.nvidia.com/cuda-toolkit-archive\n",
    "\n",
    "This video explains the process pretty well: https://www.youtube.com/watch?v=Kp6c5v9iL84\n",
    "\n",
    "Let us do a check if our GPU is recognized by PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2eaf458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA supported by this system? True\n",
      "CUDA version: 11.1\n",
      "ID of current CUDA device:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "  \n",
    "print(f\"Is CUDA supported by this system? {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "  \n",
    "# Storing ID of current CUDA device\n",
    "cuda_id = torch.cuda.current_device()\n",
    "print(f\"ID of current CUDA device:{torch.cuda.current_device()}\")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9e269f",
   "metadata": {},
   "source": [
    "As of writing, I have now made the change to upgrade my CUDA version from 11.1 to 11.8. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7232953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA supported by this system? True\n",
      "CUDA version: 11.8\n",
      "ID of current CUDA device:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "  \n",
    "print(f\"Is CUDA supported by this system? {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "  \n",
    "# Storing ID of current CUDA device\n",
    "cuda_id = torch.cuda.current_device()\n",
    "print(f\"ID of current CUDA device:{torch.cuda.current_device()}\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbebbcf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Apr 11 21:19:40 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 531.14                 Driver Version: 531.14       CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                      TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1660 T...  WDDM | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   44C    P8                4W /  N/A|      0MiB /  6144MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acae33e",
   "metadata": {},
   "source": [
    "Doing these tests and having the results as shown proves that the GPU is up and running. Please take note that this only applies if you have an NVIDIA GPU, so it may be best to consult other alternatives if you have an AMD GPU. \n",
    "\n",
    "Let us now set up the YOLOv8 repository. The key difference here is that everything is made convenient by just running one line of code. This code installs all the dependencies and libraries needed to run YOLOv8:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39aab3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2929def7",
   "metadata": {},
   "source": [
    "**NOTE** \n",
    "\n",
    "By running this line of code, it actually installs the CPU version of PyTorch, so we will need to modify our code to have it install the GPU version. We only need to run the pip install one time.\n",
    "\n",
    "\n",
    "To install the GPU version, we will need to go back to the PyTorch installation link (https://pytorch.org/get-started/locally/) and copy the code in our Anaconda Prompt. The difference is that we will just upgrade it. To do so, add \"--upgrade \" after install in your command prompt.\n",
    "\n",
    "The upgrade code should look like this if you are upgrading to CUDA 11.8:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797a21c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip3 install --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83f88de",
   "metadata": {},
   "source": [
    "What we recommend is to do pip install ultralytics first, and then install the GPU version of PyTorch to make things more efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db43609a",
   "metadata": {},
   "source": [
    "Here are the documentations for YOLOv8:\n",
    "\n",
    "**GitHub Link**: https://github.com/ultralytics/ultralytics/blob/main/README.md\n",
    "\n",
    "**Official Documentation**: https://docs.ultralytics.com/#yolo-a-brief-history\n",
    "\n",
    "Let us now do a quick check to see if YOLOv8 is connected with our GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82f616bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2K\n",
      "\u001B[2K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.58  Python-3.9.7 torch-2.0.0+cu118 CUDA:0 (NVIDIA GeForce GTX 1660 Ti with Max-Q Design, 6144MiB)\n",
      "Setup complete  (16 CPUs, 15.4 GB RAM, 345.6/458.4 GB disk)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "!yolo checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cc23bf",
   "metadata": {},
   "source": [
    "YOLOv8 is now set-up to run with our local GPU with CUDA version 11.8.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0101546b",
   "metadata": {},
   "source": [
    "## TRAINING THE MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a84f52",
   "metadata": {},
   "source": [
    "With everything set-up, we can now prepare to train the model. We can run this in 2 ways: Command Line Interface and Python style. Personally, CLI is easier to run and is less prone to errors as of writing. \n",
    "\n",
    "Before running the CLI (Command Line Interface), it is important to note the following:\n",
    "\n",
    "1.) There is no need to zip the images. A thing of note is that the labels and images have to be in a separate folder. To do this you can create a folder named \"labels\" and change the directory in LabelImg to that folder. \n",
    "\n",
    "2.) A YAML file is needed, as this acts as our \"repository\", which contains the file paths of the train and validation images, the number of classes, as well as the class definitions. We can create this through code, or we can do it manually through a text editor. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fd67e1",
   "metadata": {},
   "source": [
    "3.) Batch size may need to be reduced, as there are instances where we will have a runtime error due to the GPU having too low RAM, but this depends on how many VRAM does your GPU have.  \n",
    "\n",
    "4.) The number of epochs may vary depending on the number of images, but for 500 images, 50-100 epochs is acceptable. There have been instances where there is early stoppage due to the accuracy not increasing, but we can always set a custom value by adding \"patience = x\". \n",
    "\n",
    "5.) To save the results in a folder, add \"save=True\" to your CLI or Python script, as there are instances where it did the results were not saved. \n",
    "\n",
    "Once we have these all ready, let us now train our model, which is essentially reduced to 1 line and can be run on either a notebook or on command prompt:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d12e34d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=train amp =False epochs=100 data=data_custom.yaml model=yolov8x.pt imgsz=640 batch=16 save=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2178b594",
   "metadata": {},
   "source": [
    "Here is a guide on how to set-up YOLOv8 and briefly explains the whole process: https://www.youtube.com/watch?v=gRAyOPjQ9_s&t=1s\n",
    "\n",
    "Optimizing and tuning the hyperparameters is a different story. Here is a link on the hyperparameters present for training the data: https://docs.ultralytics.com/modes/train/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6def768c",
   "metadata": {},
   "source": [
    "## TESTING OUT THE MODEL USING VALIDATION IMAGES "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d811950",
   "metadata": {},
   "source": [
    "Now that we have our model, let us now do predictions on a validation dataset. \n",
    "\n",
    "We will now use a different mode, which is \"predict\", while our model is the one that was created in the \"train\" folder. \n",
    "\n",
    "You can also set your labels to only show its labels based on a minimum confidence percentage (e.g. you want the model to only show labels with at least 50% confidence). To do this, set conf = 0.5 (you can change this number depending on your needs).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d63047e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.58  Python-3.9.7 torch-1.9.0+cu111 CUDA:0 (NVIDIA GeForce GTX 1660 Ti with Max-Q Design, 6144MiB)\n",
      "D:\\Learnings\\Anaconda\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "Model summary (fused): 268 layers, 68125494 parameters, 0 gradients, 257.4 GFLOPs\n",
      "\n",
      "image 1/10 C:\\Users\\Patrick\\Desktop\\CPSC_4830\\Garbage_Detection_Project\\255_images\\val\\images\\IMG_0133.jpg: 640x480 4 non_organics, 80.4ms\n",
      "image 2/10 C:\\Users\\Patrick\\Desktop\\CPSC_4830\\Garbage_Detection_Project\\255_images\\val\\images\\IMG_0134.jpg: 640x480 3 non_organics, 76.4ms\n",
      "image 3/10 C:\\Users\\Patrick\\Desktop\\CPSC_4830\\Garbage_Detection_Project\\255_images\\val\\images\\IMG_0135.jpg: 640x480 3 non_organics, 75.4ms\n",
      "image 4/10 C:\\Users\\Patrick\\Desktop\\CPSC_4830\\Garbage_Detection_Project\\255_images\\val\\images\\IMG_0136.jpg: 640x480 5 non_organics, 76.2ms\n",
      "image 5/10 C:\\Users\\Patrick\\Desktop\\CPSC_4830\\Garbage_Detection_Project\\255_images\\val\\images\\IMG_0137.jpg: 640x480 3 non_organics, 75.4ms\n",
      "image 6/10 C:\\Users\\Patrick\\Desktop\\CPSC_4830\\Garbage_Detection_Project\\255_images\\val\\images\\IMG_1567.jpg: 480x640 4 non_organics, 86.8ms\n",
      "image 7/10 C:\\Users\\Patrick\\Desktop\\CPSC_4830\\Garbage_Detection_Project\\255_images\\val\\images\\IMG_1568.jpg: 480x640 (no detections), 85.2ms\n",
      "image 8/10 C:\\Users\\Patrick\\Desktop\\CPSC_4830\\Garbage_Detection_Project\\255_images\\val\\images\\IMG_1569.jpg: 480x640 4 organics, 84.7ms\n",
      "image 9/10 C:\\Users\\Patrick\\Desktop\\CPSC_4830\\Garbage_Detection_Project\\255_images\\val\\images\\IMG_1570.jpg: 480x640 1 organic, 87.8ms\n",
      "image 10/10 C:\\Users\\Patrick\\Desktop\\CPSC_4830\\Garbage_Detection_Project\\255_images\\val\\images\\IMG_1571.jpg: 480x640 4 non_organics, 84.4ms\n",
      "Speed: 0.7ms preprocess, 81.3ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001B[1mruns\\detect\\predict\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "yolo task=detect mode=predict model=best_535.pt source='C:/Users/Patrick/Desktop/CPSC_4830/Garbage_Detection_Project/yolov8/535images/val/images' save=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91421e49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
